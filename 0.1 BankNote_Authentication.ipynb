{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.621600</td>\n",
       "      <td>8.66610</td>\n",
       "      <td>-2.80730</td>\n",
       "      <td>-0.446990</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.545900</td>\n",
       "      <td>8.16740</td>\n",
       "      <td>-2.45860</td>\n",
       "      <td>-1.462100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.866000</td>\n",
       "      <td>-2.63830</td>\n",
       "      <td>1.92420</td>\n",
       "      <td>0.106450</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.456600</td>\n",
       "      <td>9.52280</td>\n",
       "      <td>-4.01120</td>\n",
       "      <td>-3.594400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.329240</td>\n",
       "      <td>-4.45520</td>\n",
       "      <td>4.57180</td>\n",
       "      <td>-0.988800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.368400</td>\n",
       "      <td>9.67180</td>\n",
       "      <td>-3.96060</td>\n",
       "      <td>-3.162500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.591200</td>\n",
       "      <td>3.01290</td>\n",
       "      <td>0.72888</td>\n",
       "      <td>0.564210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.092200</td>\n",
       "      <td>-6.81000</td>\n",
       "      <td>8.46360</td>\n",
       "      <td>-0.602160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.203200</td>\n",
       "      <td>5.75880</td>\n",
       "      <td>-0.75345</td>\n",
       "      <td>-0.612510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.535600</td>\n",
       "      <td>9.17720</td>\n",
       "      <td>-2.27180</td>\n",
       "      <td>-0.735350</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.224700</td>\n",
       "      <td>8.77790</td>\n",
       "      <td>-2.21350</td>\n",
       "      <td>-0.806470</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.989900</td>\n",
       "      <td>-2.70660</td>\n",
       "      <td>2.39460</td>\n",
       "      <td>0.862910</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.899300</td>\n",
       "      <td>7.66250</td>\n",
       "      <td>0.15394</td>\n",
       "      <td>-3.110800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-1.576800</td>\n",
       "      <td>10.84300</td>\n",
       "      <td>2.54620</td>\n",
       "      <td>-2.936200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.404000</td>\n",
       "      <td>8.72610</td>\n",
       "      <td>-2.99150</td>\n",
       "      <td>-0.572420</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.676500</td>\n",
       "      <td>-3.38950</td>\n",
       "      <td>3.48960</td>\n",
       "      <td>1.477100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.671900</td>\n",
       "      <td>3.06460</td>\n",
       "      <td>0.37158</td>\n",
       "      <td>0.586190</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.803550</td>\n",
       "      <td>2.84730</td>\n",
       "      <td>4.34390</td>\n",
       "      <td>0.601700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.447900</td>\n",
       "      <td>-4.87940</td>\n",
       "      <td>8.34280</td>\n",
       "      <td>-2.108600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.242300</td>\n",
       "      <td>11.02720</td>\n",
       "      <td>-4.35300</td>\n",
       "      <td>-4.101300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.786700</td>\n",
       "      <td>7.89020</td>\n",
       "      <td>-2.61960</td>\n",
       "      <td>-0.487080</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.329200</td>\n",
       "      <td>-4.45520</td>\n",
       "      <td>4.57180</td>\n",
       "      <td>-0.988800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.936200</td>\n",
       "      <td>10.16220</td>\n",
       "      <td>-3.82350</td>\n",
       "      <td>-4.017200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.935840</td>\n",
       "      <td>8.88550</td>\n",
       "      <td>-1.68310</td>\n",
       "      <td>-1.659900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.433800</td>\n",
       "      <td>9.88700</td>\n",
       "      <td>-4.67950</td>\n",
       "      <td>-3.748300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.705700</td>\n",
       "      <td>-5.49810</td>\n",
       "      <td>8.33680</td>\n",
       "      <td>-2.871500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.143200</td>\n",
       "      <td>-3.74130</td>\n",
       "      <td>5.57770</td>\n",
       "      <td>-0.635780</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.382140</td>\n",
       "      <td>8.39090</td>\n",
       "      <td>2.16240</td>\n",
       "      <td>-3.740500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6.563300</td>\n",
       "      <td>9.81870</td>\n",
       "      <td>-4.41130</td>\n",
       "      <td>-3.225800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.890600</td>\n",
       "      <td>-3.35840</td>\n",
       "      <td>3.42020</td>\n",
       "      <td>1.090500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.248110</td>\n",
       "      <td>-0.17797</td>\n",
       "      <td>4.90680</td>\n",
       "      <td>0.154290</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.488400</td>\n",
       "      <td>3.62740</td>\n",
       "      <td>3.30800</td>\n",
       "      <td>0.489210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>4.296900</td>\n",
       "      <td>7.61700</td>\n",
       "      <td>-2.38740</td>\n",
       "      <td>-0.961640</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-0.965110</td>\n",
       "      <td>9.41110</td>\n",
       "      <td>1.73050</td>\n",
       "      <td>-4.862900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-1.616200</td>\n",
       "      <td>0.80908</td>\n",
       "      <td>8.16280</td>\n",
       "      <td>0.608170</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2.439100</td>\n",
       "      <td>6.44170</td>\n",
       "      <td>-0.80743</td>\n",
       "      <td>-0.691390</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2.688100</td>\n",
       "      <td>6.01950</td>\n",
       "      <td>-0.46641</td>\n",
       "      <td>-0.692680</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3.628900</td>\n",
       "      <td>0.81322</td>\n",
       "      <td>1.62770</td>\n",
       "      <td>0.776270</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4.567900</td>\n",
       "      <td>3.19290</td>\n",
       "      <td>-2.10550</td>\n",
       "      <td>0.296530</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3.480500</td>\n",
       "      <td>9.70080</td>\n",
       "      <td>-3.75410</td>\n",
       "      <td>-3.437900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4.171100</td>\n",
       "      <td>8.72200</td>\n",
       "      <td>-3.02240</td>\n",
       "      <td>-0.596990</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>-0.206200</td>\n",
       "      <td>9.22070</td>\n",
       "      <td>-3.70440</td>\n",
       "      <td>-6.810300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-0.006892</td>\n",
       "      <td>9.29310</td>\n",
       "      <td>-0.41243</td>\n",
       "      <td>-1.963800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.964410</td>\n",
       "      <td>5.83950</td>\n",
       "      <td>2.32350</td>\n",
       "      <td>0.066365</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2.856100</td>\n",
       "      <td>6.91760</td>\n",
       "      <td>-0.79372</td>\n",
       "      <td>0.484030</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-0.786900</td>\n",
       "      <td>9.56630</td>\n",
       "      <td>-3.78670</td>\n",
       "      <td>-7.503400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2.084300</td>\n",
       "      <td>6.62580</td>\n",
       "      <td>0.48382</td>\n",
       "      <td>-2.213400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>-0.786900</td>\n",
       "      <td>9.56630</td>\n",
       "      <td>-3.78670</td>\n",
       "      <td>-7.503400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>3.910200</td>\n",
       "      <td>6.06500</td>\n",
       "      <td>-2.45340</td>\n",
       "      <td>-0.682340</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.634900</td>\n",
       "      <td>3.28600</td>\n",
       "      <td>2.87530</td>\n",
       "      <td>0.087054</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>4.323900</td>\n",
       "      <td>-4.88350</td>\n",
       "      <td>3.43560</td>\n",
       "      <td>-0.577600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>5.262000</td>\n",
       "      <td>3.98340</td>\n",
       "      <td>-1.55720</td>\n",
       "      <td>1.010300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>3.145200</td>\n",
       "      <td>5.82500</td>\n",
       "      <td>-0.51439</td>\n",
       "      <td>-1.494400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2.549000</td>\n",
       "      <td>6.14990</td>\n",
       "      <td>-1.16050</td>\n",
       "      <td>-1.237100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>4.926400</td>\n",
       "      <td>5.49600</td>\n",
       "      <td>-2.47740</td>\n",
       "      <td>-0.506480</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    variance  skewness  curtosis   entropy  class\n",
       "0   3.621600   8.66610  -2.80730 -0.446990      0\n",
       "1   4.545900   8.16740  -2.45860 -1.462100      0\n",
       "2   3.866000  -2.63830   1.92420  0.106450      0\n",
       "3   3.456600   9.52280  -4.01120 -3.594400      0\n",
       "4   0.329240  -4.45520   4.57180 -0.988800      0\n",
       "5   4.368400   9.67180  -3.96060 -3.162500      0\n",
       "6   3.591200   3.01290   0.72888  0.564210      0\n",
       "7   2.092200  -6.81000   8.46360 -0.602160      0\n",
       "8   3.203200   5.75880  -0.75345 -0.612510      0\n",
       "9   1.535600   9.17720  -2.27180 -0.735350      0\n",
       "10  1.224700   8.77790  -2.21350 -0.806470      0\n",
       "11  3.989900  -2.70660   2.39460  0.862910      0\n",
       "12  1.899300   7.66250   0.15394 -3.110800      0\n",
       "13 -1.576800  10.84300   2.54620 -2.936200      0\n",
       "14  3.404000   8.72610  -2.99150 -0.572420      0\n",
       "15  4.676500  -3.38950   3.48960  1.477100      0\n",
       "16  2.671900   3.06460   0.37158  0.586190      0\n",
       "17  0.803550   2.84730   4.34390  0.601700      0\n",
       "18  1.447900  -4.87940   8.34280 -2.108600      0\n",
       "19  5.242300  11.02720  -4.35300 -4.101300      0\n",
       "20  5.786700   7.89020  -2.61960 -0.487080      0\n",
       "21  0.329200  -4.45520   4.57180 -0.988800      0\n",
       "22  3.936200  10.16220  -3.82350 -4.017200      0\n",
       "23  0.935840   8.88550  -1.68310 -1.659900      0\n",
       "24  4.433800   9.88700  -4.67950 -3.748300      0\n",
       "25  0.705700  -5.49810   8.33680 -2.871500      0\n",
       "26  1.143200  -3.74130   5.57770 -0.635780      0\n",
       "27 -0.382140   8.39090   2.16240 -3.740500      0\n",
       "28  6.563300   9.81870  -4.41130 -3.225800      0\n",
       "29  4.890600  -3.35840   3.42020  1.090500      0\n",
       "30 -0.248110  -0.17797   4.90680  0.154290      0\n",
       "31  1.488400   3.62740   3.30800  0.489210      0\n",
       "32  4.296900   7.61700  -2.38740 -0.961640      0\n",
       "33 -0.965110   9.41110   1.73050 -4.862900      0\n",
       "34 -1.616200   0.80908   8.16280  0.608170      0\n",
       "35  2.439100   6.44170  -0.80743 -0.691390      0\n",
       "36  2.688100   6.01950  -0.46641 -0.692680      0\n",
       "37  3.628900   0.81322   1.62770  0.776270      0\n",
       "38  4.567900   3.19290  -2.10550  0.296530      0\n",
       "39  3.480500   9.70080  -3.75410 -3.437900      0\n",
       "40  4.171100   8.72200  -3.02240 -0.596990      0\n",
       "41 -0.206200   9.22070  -3.70440 -6.810300      0\n",
       "42 -0.006892   9.29310  -0.41243 -1.963800      0\n",
       "43  0.964410   5.83950   2.32350  0.066365      0\n",
       "44  2.856100   6.91760  -0.79372  0.484030      0\n",
       "45 -0.786900   9.56630  -3.78670 -7.503400      0\n",
       "46  2.084300   6.62580   0.48382 -2.213400      0\n",
       "47 -0.786900   9.56630  -3.78670 -7.503400      0\n",
       "48  3.910200   6.06500  -2.45340 -0.682340      0\n",
       "49  1.634900   3.28600   2.87530  0.087054      0\n",
       "50  4.323900  -4.88350   3.43560 -0.577600      0\n",
       "51  5.262000   3.98340  -1.55720  1.010300      0\n",
       "52  3.145200   5.82500  -0.51439 -1.494400      0\n",
       "53  2.549000   6.14990  -1.16050 -1.237100      0\n",
       "54  4.926400   5.49600  -2.47740 -0.506480      0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('BankNote.csv')\n",
    "df.head(55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          variance     skewness     curtosis      entropy        class\n",
      "count  1372.000000  1372.000000  1372.000000  1372.000000  1372.000000\n",
      "mean      0.433735     1.922353     1.397627    -1.191657     0.444606\n",
      "std       2.842763     5.869047     4.310030     2.101013     0.497103\n",
      "min      -7.042100   -13.773100    -5.286100    -8.548200     0.000000\n",
      "25%      -1.773000    -1.708200    -1.574975    -2.413450     0.000000\n",
      "50%       0.496180     2.319650     0.616630    -0.586650     0.000000\n",
      "75%       2.821475     6.814625     3.179250     0.394810     1.000000\n",
      "max       6.824800    12.951600    17.927400     2.449500     1.000000\n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1372, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2123c45fda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df[['variance', 'skewness', 'curtosis', 'entropy']]\n",
    "Y= df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "X = X.astype('float32')\n",
    "\n",
    "Y = LabelEncoder().fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variance    float64\n",
       "skewness    float64\n",
       "curtosis    float64\n",
       "entropy     float64\n",
       "class         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1097, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "35/35 [==============================] - 1s 2ms/step - loss: 1.7465 - accuracy: 0.5880\n",
      "Epoch 2/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 1.3401 - accuracy: 0.6272\n",
      "Epoch 3/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 1.0389 - accuracy: 0.6600\n",
      "Epoch 4/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.8023 - accuracy: 0.6964\n",
      "Epoch 5/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.6032 - accuracy: 0.7356\n",
      "Epoch 6/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7767\n",
      "Epoch 7/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3423 - accuracy: 0.8396\n",
      "Epoch 8/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2792 - accuracy: 0.8861\n",
      "Epoch 9/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2402 - accuracy: 0.9098\n",
      "Epoch 10/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2135 - accuracy: 0.9170\n",
      "Epoch 11/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1924 - accuracy: 0.9262\n",
      "Epoch 12/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1746 - accuracy: 0.9325\n",
      "Epoch 13/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1594 - accuracy: 0.9407\n",
      "Epoch 14/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1463 - accuracy: 0.9499\n",
      "Epoch 15/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1346 - accuracy: 0.9572\n",
      "Epoch 16/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1243 - accuracy: 0.9617\n",
      "Epoch 17/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1154 - accuracy: 0.9635\n",
      "Epoch 18/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1073 - accuracy: 0.9654\n",
      "Epoch 19/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1003 - accuracy: 0.9672\n",
      "Epoch 20/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0936 - accuracy: 0.9708\n",
      "Epoch 21/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0877 - accuracy: 0.9745\n",
      "Epoch 22/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0824 - accuracy: 0.9745\n",
      "Epoch 23/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0775 - accuracy: 0.9754\n",
      "Epoch 24/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0729 - accuracy: 0.9772\n",
      "Epoch 25/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0687 - accuracy: 0.9799\n",
      "Epoch 26/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0646 - accuracy: 0.9845\n",
      "Epoch 27/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0610 - accuracy: 0.9854\n",
      "Epoch 28/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0578 - accuracy: 0.9872\n",
      "Epoch 29/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0546 - accuracy: 0.9900\n",
      "Epoch 30/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9900\n",
      "Epoch 31/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0490 - accuracy: 0.9900\n",
      "Epoch 32/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0466 - accuracy: 0.9909\n",
      "Epoch 33/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0441 - accuracy: 0.9918\n",
      "Epoch 34/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0421 - accuracy: 0.9918\n",
      "Epoch 35/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0400 - accuracy: 0.9918\n",
      "Epoch 36/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0380 - accuracy: 0.9927\n",
      "Epoch 37/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 0.9945\n",
      "Epoch 38/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0346 - accuracy: 0.9973\n",
      "Epoch 39/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0331 - accuracy: 0.9982\n",
      "Epoch 40/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0315 - accuracy: 0.9982\n",
      "Epoch 41/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0301 - accuracy: 0.9982\n",
      "Epoch 42/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0289 - accuracy: 0.9982\n",
      "Epoch 43/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0277 - accuracy: 0.9982\n",
      "Epoch 44/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0266 - accuracy: 0.9982\n",
      "Epoch 45/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0255 - accuracy: 0.9982\n",
      "Epoch 46/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0245 - accuracy: 0.9982\n",
      "Epoch 47/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0235 - accuracy: 0.9991\n",
      "Epoch 48/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0227 - accuracy: 0.9991\n",
      "Epoch 49/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0218 - accuracy: 0.9991\n",
      "Epoch 50/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0210 - accuracy: 0.9991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2124143bd68>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "     keras.layers.Dense(12, input_shape=(4,), activation='relu',kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0245 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.024498526006937027, 1.0]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>-1.38850</td>\n",
       "      <td>12.5026</td>\n",
       "      <td>0.691180</td>\n",
       "      <td>-7.548700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>2.77440</td>\n",
       "      <td>6.8576</td>\n",
       "      <td>-1.067100</td>\n",
       "      <td>0.075416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>-4.28870</td>\n",
       "      <td>-7.8633</td>\n",
       "      <td>11.838700</td>\n",
       "      <td>-1.897800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>5.35860</td>\n",
       "      <td>3.7557</td>\n",
       "      <td>-1.734500</td>\n",
       "      <td>1.078900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>0.75736</td>\n",
       "      <td>3.0294</td>\n",
       "      <td>2.916400</td>\n",
       "      <td>-0.068117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>-3.72440</td>\n",
       "      <td>1.9037</td>\n",
       "      <td>-0.035421</td>\n",
       "      <td>-2.509500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>4.64990</td>\n",
       "      <td>7.6336</td>\n",
       "      <td>-1.942700</td>\n",
       "      <td>-0.374580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>-2.21730</td>\n",
       "      <td>1.4671</td>\n",
       "      <td>-0.726890</td>\n",
       "      <td>-1.172400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>4.92640</td>\n",
       "      <td>5.4960</td>\n",
       "      <td>-2.477400</td>\n",
       "      <td>-0.506480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>0.58982</td>\n",
       "      <td>7.4266</td>\n",
       "      <td>1.235300</td>\n",
       "      <td>-2.959500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      variance  skewness   curtosis   entropy\n",
       "529   -1.38850   12.5026   0.691180 -7.548700\n",
       "243    2.77440    6.8576  -1.067100  0.075416\n",
       "1309  -4.28870   -7.8633  11.838700 -1.897800\n",
       "664    5.35860    3.7557  -1.734500  1.078900\n",
       "745    0.75736    3.0294   2.916400 -0.068117\n",
       "1301  -3.72440    1.9037  -0.035421 -2.509500\n",
       "746    4.64990    7.6336  -1.942700 -0.374580\n",
       "873   -2.21730    1.4671  -0.726890 -1.172400\n",
       "54     4.92640    5.4960  -2.477400 -0.506480\n",
       "405    0.58982    7.4266   1.235300 -2.959500"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.2429059e-03],\n",
       "       [5.5981278e-02],\n",
       "       [3.3023745e-02],\n",
       "       [1.2060598e-06],\n",
       "       [4.2030811e-03]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yp = model.predict(X_test)\n",
    "yp[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45309612\n"
     ]
    }
   ],
   "source": [
    "print(yp.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for element in yp:\n",
    "    if element > 0.45309612:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1,w2,w3,w4= model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.9246914   0.5732207   0.17197607  1.1270701   0.4875333   0.5153485\n",
      "  -0.35331818 -0.33735156 -0.57730347  0.1201503  -0.25372025 -0.73856664]\n",
      " [-0.25166947  0.32066733  0.9408856  -0.79499143 -0.75554657  0.03869837\n",
      "   0.4334048   0.4415936  -0.10538311 -0.03596521  0.75141984 -0.8002596 ]\n",
      " [-0.09607437  0.48512873 -0.40754864 -0.14565101 -0.07228214  0.784357\n",
      "  -0.48897707  1.2499436   0.984651   -0.43116274 -1.736251   -0.72212595]\n",
      " [ 0.48797417 -0.5090547   0.33402228  0.10015399  0.68227345 -0.12529452\n",
      "  -0.85411584 -0.21823306  1.5794324  -1.2765712  -0.39196742 -0.8295625 ]] [ 1.0251514   0.19415729 -0.44699162 -0.39264578 -0.0964286   0.30277264\n",
      " -0.521719   -0.14228353 -0.14819722  0.14087705  0.7254594   0.8048576 ] [[ 0.6551118 ]\n",
      " [-1.1758116 ]\n",
      " [-0.61794364]\n",
      " [-0.13927801]\n",
      " [ 0.26277775]\n",
      " [-0.6074908 ]\n",
      " [-0.36474082]\n",
      " [-0.03688918]\n",
      " [ 0.30092838]\n",
      " [ 0.30762503]\n",
      " [ 0.4320652 ]\n",
      " [ 0.97303224]] [0.11252304]\n"
     ]
    }
   ],
   "source": [
    "print(w1,w2,w3,w4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
